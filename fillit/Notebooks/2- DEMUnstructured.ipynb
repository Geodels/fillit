{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an unstructured mesh\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> In this example, we use the ESRI Grid for Australia available from Geoscience Australia product catalogue (https://ecat.ga.gov.au/geonetwork/). You could download it when searching for **Australian Bathymetry and Topography Grid, June 2009**.  \n",
    "\n",
    "We also provide in data folder a low resolution GeoTIFF that can also be used for this tutorial (AUS_LR.tiff). \n",
    "\n",
    "\n",
    "We will first _reproject the dataset_ in UTM coordinates, then we will use _shapefiles and countours_ to clipped on region of interested and then we will use </div>\n",
    "\n",
    "\n",
    "We will create the following mesh:\n",
    "\n",
    "***\n",
    "\n",
    "<img src=\"images/australia.png\" width=\"80%\">\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "## Notebook contents\n",
    "\n",
    "   - [Converting from lon/lat to metres](#Converting-from-lon/lat-to-metres)\n",
    "   - [Clipped elevation grid](#Clipped-elevation-grid)\n",
    "   - [X & Y axes](#X-&-Y-axes)\n",
    "   - [Define contour lines](#Define-contour-lines)\n",
    "   - [Unstructured elevation grid](#Unstructured-elevation-grid)\n",
    "   - [Pit filling](#Pit-filling)\n",
    "   - [Visualisation](#Visualisation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycpt\n",
    "import lavavu\n",
    "\n",
    "from time import clock\n",
    "import fillit as pitfill\n",
    "\n",
    "import meshio\n",
    "import numpy as np\n",
    "import pygmsh as pg\n",
    "import meshplex as vpy\n",
    "\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "label_size = 8\n",
    "matplotlib.rcParams['xtick.labelsize'] = label_size \n",
    "matplotlib.rcParams['ytick.labelsize'] = label_size\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting from lon/lat to metres\n",
    "\n",
    "To reproject the grid from lon/lat coordinates to UTM (metres), two main libraries are available within the Docker image:\n",
    "\n",
    "+ `pygeotools` -- https://github.com/dshean/pygeotools\n",
    "+ `rasterio` -- https://github.com/mapbox/rasterio\n",
    "\n",
    "First, we specify our DEM filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/AUS_LR.tiff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show how this can be done using rasterio. First we load the required libraries and then define the requested projection (here we used EPSG reference for the region EPSG:28355)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio import crs\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "# Reproject to EPSG zone\n",
    "dst_crs = {'init': 'EPSG:28355'}\n",
    "\n",
    "# Requested reprojected dataset resolution (metres)\n",
    "utmRes = 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the following cell to make the projection and get the interpolated elevation points at the requested resolution (elev -- a numpy masked array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.drivers(CHECK_WITH_INVERT_PROJ=True):\n",
    "    with rasterio.open(filename) as src:\n",
    "        \n",
    "        profile = src.profile\n",
    "        if src.nodata is None:\n",
    "            nodata = -32768.0\n",
    "        else:\n",
    "            nodata = src.nodata\n",
    "        \n",
    "        # Calculate the ideal dimensions and transformation in the new crs\n",
    "        dst_affine, dst_width, dst_height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds, resolution=utmRes)\n",
    "\n",
    "        # update the relevant parts of the profile\n",
    "        profile.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': dst_affine,\n",
    "            'affine': dst_affine,\n",
    "            'width': dst_width,\n",
    "            'height': dst_height\n",
    "        })\n",
    "\n",
    "        # Reproject and write each band\n",
    "        src_array = src.read()\n",
    "        dst_array = np.empty((int(dst_height), int(dst_width)), dtype='int16')\n",
    "\n",
    "        reproject(\n",
    "                # Source parameters\n",
    "                source=src_array,\n",
    "                src_crs=src.crs,\n",
    "                src_transform=src.affine,\n",
    "                src_nodata=nodata,\n",
    "\n",
    "                # Destination paramaters\n",
    "                destination=dst_array,\n",
    "                dst_transform=dst_affine,\n",
    "                dst_crs=dst_crs,\n",
    "                dst_nodata=nodata,\n",
    "\n",
    "                # Configuration\n",
    "                resampling=Resampling.nearest,\n",
    "                num_threads=2)\n",
    "\n",
    "        elev = np.ma.masked_where(dst_array == nodata, dst_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the metadata associated with the new GeoTIFF file using for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clipped elevation grid\n",
    "\n",
    "We can visualise the new elevation array using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotElevation( data, cmin, cmax, colormap):\n",
    "    '''\n",
    "    data: dataset to plot\n",
    "    zmin,zmax: extent of the colormap\n",
    "    colormap: to use    \n",
    "    '''\n",
    "    \n",
    "    # Figure size is defined here\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(data, interpolation='nearest', cmap=colormap,\n",
    "                     vmin=cmin, vmax=cmax)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    cbar = plt.colorbar(im,cax=cax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to use pycpt -- Python tools to load and handle cpt (GMT format) color maps for use with matplotlib (e.g. from cpt-city)\n",
    "You can pick a colorbar from the following website:\n",
    "    \n",
    "- http://soliton.vm.bytemark.co.uk/pub/cpt-city/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topocmap = pycpt.load.cmap_from_cptcity_url('gmt/GMT_globe.cpt')\n",
    "plotElevation( elev, -10000, 10350, topocmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the figure above, we will need to clip our array to remove the nodata values induced by the reprojection... We do that by just selecting the extent of the rows and columns number from our elev numpy array..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotElevation( elev[20:410,40:], -10000, 10350, topocmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then defined a new elevation array dem based on the clipped one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = elev[20:410,40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X & Y axes\n",
    "\n",
    "To keep your coordinates system for post-processing and to potentially reproject the outputs from the landscape evolution model in another geospatial system we needs to specify the X and Y axes.\n",
    "We do it like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xMin = dst_affine[2]\n",
    "xMax = dst_affine[2] + abs(dst_affine[0])*dst_width\n",
    "\n",
    "yMin = dst_affine[5] - abs(dst_affine[4])*dst_height\n",
    "yMax = dst_affine[5]\n",
    "\n",
    "print(\"Initial DEM:\\n\")\n",
    "\n",
    "print(\"Lower left coordinates       Xmin: {}, Ymin: {}\".format(xMin,yMin))\n",
    "print(\"Upper right coordinates      Xmax:  {}, Ymax: {}\".format(xMax,yMax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the X and Y coordinates, at this point we can choose to decrease the resolution if needed by using the step parameter (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 2\n",
    "spacing = utmRes*step\n",
    "\n",
    "Z = dem[::step,::step]\n",
    "\n",
    "nx = Z.shape[1]\n",
    "ny = Z.shape[0]\n",
    "\n",
    "minX, maxX = xMin, xMin+spacing*nx\n",
    "minY, maxY = yMin, yMin+spacing*ny\n",
    "\n",
    "xcoords = np.arange(minX, maxX, spacing)\n",
    "ycoords = np.arange(minY, maxY, spacing)\n",
    "\n",
    "X, Y = np.meshgrid(xcoords, ycoords)\n",
    "\n",
    "coords = np.vstack([X.ravel(), Y.ravel()])\n",
    "\n",
    "print(\"Clipped DEM:\\n\")\n",
    "\n",
    "print(\"Resolution (m)            res: {}\".format(spacing))\n",
    "print(\"Number of points         nbpt: {}\".format(coords.shape[0]))\n",
    "print(\"Elevation map shape        nx: {}, ny: {}\\n\".format(nx,ny))\n",
    "\n",
    "print(\"Lower left coordinates   Xmin: {}, Ymin: {}\".format(minX,minY))\n",
    "print(\"Upper right coordinates  Xmax: {}, Ymax: {}\".format(maxX,maxY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define contour lines\n",
    "\n",
    "From the projected digital elevation, we will extract contour lines at given depth and use these lines to define the extent of our simulation region and its resolution. \n",
    "\n",
    "First we define the `extractContours` function that returns the list of countour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractContours( X, Y, Z, cmin, cmax, colormap, ctrlist):\n",
    "    '''\n",
    "    coords: coordinate points (X,Y,X)\n",
    "    cmin,cmax: extent of the colormap\n",
    "    colormap: color scale to use\n",
    "    ctrlist: list of contours to extract\n",
    "    '''\n",
    "    # Figure size is defined here\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    ctrs = []\n",
    "    for k in range(len(ctrlist)):\n",
    "        ctrs.append(plt.contour(X, Y, \n",
    "                    np.flipud(Z), ctrlist[k]))\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(Z, interpolation='nearest', cmap=colormap,\n",
    "                     vmin=cmin, vmax=cmax,extent=[minX, maxX,minY, maxY])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    cbar = plt.colorbar(im,cax=cax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return ctrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we specify a list of contour line depths `ctrList` that needs to be defined in **ascending order** (this is important for what follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrList = [-1000.,500.]\n",
    "\n",
    "# Now we extract the contours lines using the previous function\n",
    "if sorted(ctrList) == ctrList:\n",
    "    ctrs = extractContours(X, Y, Z, -10000, 10350, topocmap, ctrList)\n",
    "else:\n",
    "    print(\"ERROR:\")\n",
    "    print(\"The list of contour positions needs to be specify in ascending order!\")\n",
    "    print(\"Redefine the ctrList variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the figure above that we have several contour lines for any single depth. We will only use the **longest lines for each depth** to define our simulation domain.\n",
    "\n",
    "To do so we will define two functions:\n",
    "+ `distancePts`: that will be used to get the euclidian distance between 2 points\n",
    "+ `getLongestContoursXY`: that extract the longest lines and resample it based on a characteristic length `lcar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancePts(p1,p2):\n",
    "    '''\n",
    "    Compute the euclidian distance between 2 points (p1, p2)\n",
    "    \n",
    "    '''\n",
    "    return (p1[1]-p2[1])**2+(p1[0]-p2[0])**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLongestContoursXY(ctrs, lcar):\n",
    "    '''\n",
    "    1- Extract from the list of contour points the longest path\n",
    "    2- Using a characteristic length (lcar) resample the path \n",
    "    3- Return the XY coordinates of the longest paths\n",
    "    '''\n",
    "\n",
    "    ctrPoints = []\n",
    "    # Loop through the contour lines \n",
    "    for ct in range(len(ctrs)):\n",
    "        cpath = []\n",
    "        k = 0\n",
    "        maxpts = 0\n",
    "        pathID = 0\n",
    "        \n",
    "        # For each contour extract the longest path\n",
    "        for collection in ctrs[ct].collections:\n",
    "            for path in collection.get_paths():\n",
    "                if len(path)>4:\n",
    "                    cpath.append(np.asarray(path.to_polygons()[0]))\n",
    "                    # Storing longest path\n",
    "                    if cpath[-1].shape[0] > maxpts:\n",
    "                        maxpts =  cpath[-1].shape[0]\n",
    "                        pathID = k\n",
    "                    k += 1\n",
    "\n",
    "        # Find longest path XY coordinates \n",
    "        Cpts = cpath[pathID]\n",
    "        x = Cpts[:,0]\n",
    "        y = Cpts[:,1]\n",
    "        tmp = OrderedDict()\n",
    "        for pt in zip(x,y):\n",
    "            tmp.setdefault(pt[:1], pt)   \n",
    "        ctrPts = np.asarray(tmp.values())  \n",
    "\n",
    "        # Resample the path to the requested characteristic length\n",
    "        ki = 0\n",
    "        tmpPts = []\n",
    "        cumdist = 0.\n",
    "        tmpPts.append(ctrPts[0,:])\n",
    "        for k in range(1,ctrPts.shape[0]):\n",
    "            cumdist = distancePts(ctrPts[ki,:2], ctrPts[k,:2])\n",
    "            if(cumdist >= lcar):\n",
    "                tmpPts.append(ctrPts[k,:])\n",
    "                ki = k\n",
    "        ctrPoints.append(np.asarray(tmpPts))\n",
    "\n",
    "    return ctrPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getLongestContoursXY` function will return the longest line resampled points coordinates for each contour depths defined in `ctrList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrPoints = getLongestContoursXY(ctrs, 300000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the picked contour lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotContours( X, Y, Z, cmin, cmax, colormap, ctrPts):\n",
    "    '''\n",
    "    coords: coordinate points (X,Y)\n",
    "    zmin,zmax: extent of the colormap\n",
    "    colormap: to use  \n",
    "    ctrPts: coordinates of contour lines\n",
    "    '''\n",
    "    # Figure size is defined here\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    ctrs = []\n",
    "    for k in range(len(ctrPts)):\n",
    "        plt.scatter(ctrPts[k][:,0], ctrPts[k][:,1], s=0.3, c='k')\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(Z, interpolation='nearest', cmap=colormap,\n",
    "                     vmin=cmin, vmax=cmax,extent=[minX, maxX,minY, maxY])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    cbar = plt.colorbar(im,cax=cax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotContours(X, Y, Z, -10000, 10350, topocmap, ctrPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured elevation grid\n",
    "\n",
    "We use `pyGmsh` library, an interface to `Gmsh` to build our unstructured grid:\n",
    "\n",
    "+ https://github.com/nschloe/pygmsh\n",
    "\n",
    "We first initialise a `pyGmsh` instance and define some options:\n",
    "+ `gmsh_out`: verbose from Gmsh mesh creation\n",
    "+ `gmsh_args`: Gmsh command line options: http://gmsh.info/doc/texinfo/gmsh.html#Command_002dline-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = pg.built_in.Geometry()\n",
    "\n",
    "# Gmsh options\n",
    "gmsh_out = True\n",
    "gmsh_args = ['-clmin', '20000', '-smooth', '10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gmsh geometries and surface creation\n",
    "\n",
    "The resolution of the mesh is defined based on the characteristic length parameter `lcar` defined at specific points in the geometry. Here we use a coarse resolution (`lcar1`) for the boundary line (the contour at depth _-1000m_) and a higher resolution (`lcar2`) for the contour at _500m_. \n",
    "\n",
    "Each of these contours are exported as a `Gmsh` polyline geometry using the `GmeshPolyline` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GmeshPolyline(GmshGeo, ctrPts, lcar):\n",
    "    '''\n",
    "    Define a polyline for Gmsh geometry (GmshGeo) based on a list of coonected \n",
    "    points (contour line ctrPts) and a characteristic length (lcar)\n",
    "    '''\n",
    "    Points_done=dict()\n",
    "    Line_loops=dict()\n",
    "    Line_done=dict()\n",
    "\n",
    "    # 1- Contour coordinates definition\n",
    "    for i in range(ctrPts.shape[0]):\n",
    "        Points_done[i]=GmshGeo.add_point([ctrPts[i][0], ctrPts[i][1], 0.], lcar)\n",
    "\n",
    "    # 2- Lines between points definition\n",
    "    lineLoop=[]\n",
    "    for i in range(ctrPts.shape[0]):\n",
    "        if i < ctrPts.shape[0]-1:\n",
    "            Line_done[i]=GmshGeo.add_line(Points_done[i],Points_done[i+1])\n",
    "        else:\n",
    "            Line_done[i]=GmshGeo.add_line(Points_done[i],Points_done[0])\n",
    "        lineLoop.append(Line_done[i])\n",
    "\n",
    "    return GmshGeo.add_line_loop(lineLoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External contour Gmsh characteristic length\n",
    "lcar1 = 50000.\n",
    "\n",
    "# Create polyline for contour line at -1000 m depth\n",
    "polyline1 = GmeshPolyline(geom, ctrPoints[0], lcar1)\n",
    "\n",
    "# Refined region Gmsh characteristic length\n",
    "lcar2 = 20000.\n",
    "\n",
    "# Create polyline for contour line at 500 m \n",
    "polyline2 = GmeshPolyline(geom, ctrPoints[1], lcar2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gmsh` allows to combine different shapes together using _surface_ geometry and combining/removing parts of it as required. In this example, we will first create a surface at coarse resolution between the deepest contour and the second one (this is done by defining holes in the surface). \n",
    "\n",
    "Then we add to this surface a second higher resolution one that fills the central hole.  \n",
    "\n",
    "For an extensive overview of the capability of `Gmsh`, users can refer to the following documentation:\n",
    "+ http://gmsh.info/doc/texinfo/gmsh.html\n",
    "\n",
    "It is worth noting that not all the functionalities of `Gmsh` are available in the provided Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding coarse surface on the external domain of the mesh using the holes expression\n",
    "geom.add_plane_surface(polyline1,holes=[polyline2]) \n",
    "\n",
    "# Adding refined surface in the region within the second polyline\n",
    "geom.add_plane_surface(polyline2) \n",
    "\n",
    "# Generate Gmsh triangulation\n",
    "pts, cells, _, _, _ = pg.generate_mesh(geom, dim = 2, \n",
    "                                       verbose = gmsh_out,\n",
    "                                       #geo_filename='ausGmsh.geo',\n",
    "                                       extra_gmsh_arguments=gmsh_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unstructured Grid:\\n\")\n",
    "\n",
    "print(\"Number of points         nbpt: {}\".format(pts.shape[0]))\n",
    "print(\"Number of faces       nbcells: {}\".format(cells['triangle'].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step consists in defining a _bivariate spline approximation_ over the rectangular mesh (`scipy.interpolate.RectBivariateSpline`) that will be used to get the elevation on the unstructured grid vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolateFct = RectBivariateSpline(xcoords,ycoords,np.flipud(Z).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then perform the elevation interpolation on the triangulation coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation of the elevation on the triangulation\n",
    "evalZ = interpolateFct.ev(pts[:,0], pts[:,1])\n",
    "evalZ[evalZ < min(ctrList)] = min(ctrList) \n",
    "\n",
    "# Creation of the X,Y,Z coordinates of the unstructured grid\n",
    "verts = np.insert(pts[:,:2], 2, values=evalZ, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "\n",
    "Finally we use `lavavu` to visualise the new unstructured grid. It is done by using the following things:\n",
    "\n",
    "+ points coordinates (`verts`) \n",
    "+ the IDs of the connected points forming each triangle faces (`cells['triangle']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lv = lavavu.Viewer(border=True, background=\"#FFFFFF\", resolution=[700,700], near=-10.0)\n",
    "\n",
    "# Core \n",
    "lvTriG = lv.triangles(\"DelGmsh\",  wireframe=False, colour=\"#161616\", opacity=1.0)\n",
    "lvTriG.vertices(verts)\n",
    "lvTriG.indices(cells['triangle'])\n",
    "lvTriG.values(evalZ)\n",
    "lvTriG.colourmap(\"geo\", range=[-2000.,2000.])\n",
    "#cbar2.colourmap(name, discrete=True, range=[-6,6])\n",
    "lv.translation(823.959, 14666.457, -6244788.5)\n",
    "lv.rotation(-21.213, 3.086, -0.158)\n",
    "lv.scale('z', 75)\n",
    "\n",
    "lv.control.Checkbox(property='axis')\n",
    "lvTriG.control.Checkbox(property='wireframe', label=\"wireframe\")\n",
    "lv.control.Panel()\n",
    "lv.control.ObjectList()\n",
    "lvTriG.control.Range(command='scale z', range=(1,201), step=10., value=100)\n",
    "lv.control.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pit filling\n",
    "\n",
    "We will now perform pit filling using one of the available priority-flood algorithms available in `fillit`.\n",
    "\n",
    "For regular grids, the following `classes` are available:\n",
    "+ `depressionFillingZhou`\n",
    "+ `depressionFillingBarnes`\n",
    "\n",
    "***\n",
    "\n",
    "These 2 classes are based on the following papers:\n",
    "\n",
    "Barnes, Lehman, Mulla. \"Priority-Flood: An Optimal Depression-Filling and\n",
    "Watershed-Labeling Algorithm for Digital Elevation Models\". Computers & Geosciences.\n",
    "Vol 62, Jan 2014, pp 117–127 - [link](https://www.sciencedirect.com/science/article/pii/S0098300413001337)\n",
    "\n",
    "Zhou, Sun, Fu. \"An efficient variant of the Priority-Flood algorithm for filling\n",
    "depressions in raster digital elevation models\". Computers & Geosciences.\n",
    "Vol 90, Feb 2016, pp 87–96 - [link](https://www.sciencedirect.com/science/article/pii/S0098300416300553)\n",
    "\n",
    "***\n",
    "\n",
    "To call one of these classes, you will typically do as follows:\n",
    "\n",
    "``` python\n",
    "import fillit as pitfill\n",
    "\n",
    "# Class initialisation\n",
    "pitClass = pitfill.depressionFillingZhou(coords=verts,\n",
    "                                         cells=cells['triangle'],\n",
    "                                         cartesian=False,first=1)\n",
    "\n",
    "# Performing pit filling\n",
    "fillZ = pitClass.performPitFillingUnstruct()\n",
    "\n",
    "```\n",
    "\n",
    "Here we illustrate how this is done for the 2 classes...\n",
    "\n",
    "### Barnes (2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitfill.depressionFillingBarnes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = clock()\n",
    "fillB = pitfill.depressionFillingBarnes(coords=verts,eps=0.,cells=cells['triangle'],cartesian=False,first=1)\n",
    "filledB = fillB.performPitFillingUnstruct()\n",
    "\n",
    "fillB2 = pitfill.depressionFillingBarnes(Z=verts[:,2],eps=1.e-6,cells=cells['triangle'],cartesian=False,first=0)\n",
    "filledB2 = fillB2.performPitFillingUnstruct()\n",
    "\n",
    "print('\\n+ Pit filling+epsilon & Priority-flood Barnes Algorithm 2014 (%0.02f seconds)'% (clock() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhou (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = clock()\n",
    "fillZ = pitfill.depressionFillingZhou(coords=verts,cells=cells['triangle'],cartesian=False,first=1)\n",
    "filledZ = fillB2.performPitFillingUnstruct()\n",
    "\n",
    "print('\\n+ Pit filling - Priority-flood Zhou Algorithm 2016 (%0.02f seconds)'% (clock() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **lavavu** to visualise the filled elevation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the X,Y,Z coordinates of the unstructured grid\n",
    "verts2 = np.insert(pts[:,:2], 2, values=filledB2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = lavavu.Viewer(border=True, background=\"#FFFFFF\", resolution=[700,700], near=-10.0)\n",
    "\n",
    "# Core \n",
    "lvTriG = lv.triangles(\"DelGmsh\",  wireframe=False, colour=\"#161616\", opacity=1.0)\n",
    "lvTriG.vertices(verts2)\n",
    "lvTriG.indices(cells['triangle'])\n",
    "lvTriG.values(filledB2-evalZ)\n",
    "lvTriG.colourmap(\"polar\", range=[-100,100])\n",
    "#cbar2.colourmap(name, discrete=True, range=[-6,6])\n",
    "lv.translation(823.959, 14666.457, -6244788.5)\n",
    "lv.rotation(-21.213, 3.086, -0.158)\n",
    "lv.scale('z', 75)\n",
    "\n",
    "lv.control.Checkbox(property='axis')\n",
    "lvTriG.control.Checkbox(property='wireframe', label=\"wireframe\")\n",
    "lv.control.Panel()\n",
    "lv.control.ObjectList()\n",
    "lvTriG.control.Range(command='scale z', range=(1,201), step=10., value=100)\n",
    "lv.control.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the unstructured mesh as a **VTU** file (VTK format) using `meshio` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = meshio.Mesh(pts, cells, {'Z':filledB2})\n",
    "meshio.write(\"AUS.vtu\", mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
